# models/vlm_long.py

import sys
import os
import json
import time
from PIL import Image
import openai

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../")))

# í˜„ì¬ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í´ë” â†’ test/test_images ê²½ë¡œ ê³„ì‚°
base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
image_dir = os.path.join(base_dir, "test", "test_images")

from mobilevlm_runtime import MobileVLMRuntime

# ========== í™˜ê²½ ì„¤ì • ==========
openai.api_key = os.getenv("OPENAI_API_KEY")

# VLM ëª¨ë¸ ì´ˆê¸°í™”
runtime = MobileVLMRuntime()

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ
jsonl_path = "../logs/vlm_long_log.jsonl"
diary_txt_path = "../logs/diary_entry.txt"
# diary_mp3_path = "/home/piai/AI_project/diary/diary_entry.mp3"
os.makedirs(os.path.dirname(jsonl_path), exist_ok=True)
os.makedirs(os.path.dirname(diary_txt_path), exist_ok=True)

# ========== ì´ë¯¸ì§€ í•œ ì¥ ì²˜ë¦¬ í•¨ìˆ˜ ==========
def run_once(image_path: str, kor_command: str):
    start_total = time.time()

    prompt = f"Describe this image in one complete sentence."

    # Step 2: VLM ì¶”ë¡ 
    result, duration = runtime.run(image_path, prompt)

    # # Step 4: TTS ì €ì¥ ë° ì¬ìƒ
    # tts = gTTS(translated_back, lang='ko')
    # tts.save("output.mp3")
    # os.system("mpg123 output.mp3")

    end_total = time.time()
    total_time = end_total - start_total

    # Step 5: ì¶œë ¥
    print(f"\n Image: {image_path}")
    print(f" English Prompt: {prompt}")
    print(f" Output (EN): {result}")
    print(f" Inference Time: {duration:.2f} seconds (Model only)")
    print(f" Total Time: {total_time:.2f} seconds (Translation + Model)")

    # Step 6: JSONL ì €ì¥
    json_data = {
        "image_path": image_path,
        "output_en": result,
        "inference_time": round(duration, 2),
        "total_time": round(total_time, 2),
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }

    with open(jsonl_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(json_data, ensure_ascii=False) + "\n")

# ========== ì¼ê¸° ìƒì„± + TTS ì €ì¥ í•¨ìˆ˜ ==========
def generate_diary_and_tts():
    descriptions = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            data = json.loads(line)
            descriptions.append(data["output_en"])

    if not descriptions:
        print("ì„¤ëª…ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    joined_desc = " ".join(descriptions)
    prompt = f"""
The following are brief English descriptions generated from images. 
Please write a warm and emotional **Korean diary** that reflects a day for a visually impaired person, based on these scenes.

 Instructions:
- Write exactly **7 sentences**, each on a new line.
- Use **first-person expressions** such as "ë‚˜ëŠ”", "ì˜¤ëŠ˜ì€", "ì‚°ì±…ì„ í•˜ë‹¤ê°€", etc.
- Ensure the diary flows **in natural timeline order**, as if reflecting on a full day from morning to night.
- Use **clear and simple Korean**, easy for a visually impaired listener to understand when heard aloud.
- Emphasize **sensory experiences** such as sounds, feelings, textures, or smells over visual details.
- Avoid repeating words or describing similar things more than once.
- In the **last (7th) sentence**, clearly finish the diary by **summarizing the day emotionally** or **sharing a personal reflection**.

 Scene descriptions (in English):
{joined_desc}

 Korean Diary:
"""

    print("\nğŸ“¨ Requesting GPT for diary generation...")

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ê°ì„±ì ì¸ í•œêµ­ì–´ ì¼ê¸° ì‘ê°€ì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=500,
    )

    diary_text = response.choices[0].message.content.strip()
    print("\n ìƒì„±ëœ ì¼ê¸°:\n", diary_text)

    with open(diary_txt_path, "w", encoding="utf-8") as f:
        f.write(diary_text)

    # print("\n Converting diary to MP3...")
    # tts = gTTS(diary_text, lang='ko')
    # tts.save(diary_mp3_path)
    # print(f"\n MP3 ì €ì¥ ì™„ë£Œ: {diary_mp3_path}")

# ========== ì‹¤í–‰ ==========
if __name__ == "__main__":
    # image_dir = "../test/test_images"
    for fname in sorted(os.listdir(image_dir)):
        if fname.lower().endswith(".jpg"):
            image_path = os.path.join(image_dir, fname)
            run_once(image_path, "ì•ì— ë­ ìˆì–´?")

    generate_diary_and_tts()